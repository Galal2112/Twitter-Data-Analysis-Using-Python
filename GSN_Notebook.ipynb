{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/galal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from HanTa import HanoverTagger as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnauthorized\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweet\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     21\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m tweets:\n\u001B[1;32m     24\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend([tweet\u001B[38;5;241m.\u001B[39mfull_text])\n\u001B[1;32m     26\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(data, columns\u001B[38;5;241m=\u001B[39mcolumns)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:86\u001B[0m, in \u001B[0;36mBaseIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:286\u001B[0m, in \u001B[0;36mItemIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_index \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Reached end of current page, get the next page...\u001B[39;00m\n\u001B[0;32m--> 286\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    288\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_iterator)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:86\u001B[0m, in \u001B[0;36mBaseIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:167\u001B[0m, in \u001B[0;36mIdIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 167\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRawParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m     model \u001B[38;5;241m=\u001B[39m ModelParser()\u001B[38;5;241m.\u001B[39mparse(\n\u001B[1;32m    170\u001B[0m         data, api \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[1;32m    171\u001B[0m         payload_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_list,\n\u001B[1;32m    172\u001B[0m         payload_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_type\n\u001B[1;32m    173\u001B[0m     )\n\u001B[1;32m    174\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mparser\u001B[38;5;241m.\u001B[39mparse(\n\u001B[1;32m    175\u001B[0m         data, api \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[1;32m    176\u001B[0m         payload_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_list,\n\u001B[1;32m    177\u001B[0m         payload_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_type\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:33\u001B[0m, in \u001B[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(method)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:46\u001B[0m, in \u001B[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     44\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_list\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_list\n\u001B[1;32m     45\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_type\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_type\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:1268\u001B[0m, in \u001B[0;36mAPI.search_tweets\u001B[0;34m(self, q, **kwargs)\u001B[0m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;129m@pagination\u001B[39m(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;129m@payload\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msearch_results\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msearch_tweets\u001B[39m(\u001B[38;5;28mself\u001B[39m, q, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1194\u001B[0m     \u001B[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001B[39;00m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;124;03m                     until, since_id, max_id, include_entities)\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1266\u001B[0m \u001B[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets\u001B[39;00m\n\u001B[1;32m   1267\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msearch/tweets\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint_parameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mq\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeocode\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlang\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocale\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresult_type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcount\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muntil\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msince_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minclude_entities\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:257\u001B[0m, in \u001B[0;36mAPI.request\u001B[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadRequest(resp)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m401\u001B[39m:\n\u001B[0;32m--> 257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Unauthorized(resp)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m403\u001B[39m:\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Forbidden(resp)\n",
      "\u001B[0;31mUnauthorized\u001B[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "api_key = 'ALR6ExjYkMBfebl33tcjXyZ4s'\n",
    "api_key_secret = 'nDDTt61clONQ8isJifsLT7nqhxfjHFFlo6W8rl2SblhPMeVLk3'\n",
    "\n",
    "access_token = '2317868736-6BMg18lkng6EIY2nrSSoISburY9QcaUovk78xPY'\n",
    "access_token_secret = 'UcHtfXjvurM4dT9ZpMgvwDfZ2ukQtEGQqaLEfhueSeFyq'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "limit=500\n",
    "\n",
    "keywords = '#HaltDieFresse'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#HaltDieFresse_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = '#heute'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#heute_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = '#DankeMerkel'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#DankeMerkel_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'Fresse'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('Fresse_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'heute'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('heute_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'danke Merkel'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('danke-Merkel_tweets.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vorverarbeitung von  txt\n",
    "def removeEmojis(txt):\n",
    "     regrex_pattern = re.compile(pattern = \"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "     return regrex_pattern.sub(r'',txt)\n",
    "\n",
    "def removeMentions(txt):\n",
    "    return re.sub(r'@[A-Za-z0-9]+', '' ,txt)\n",
    "\n",
    "def removeHashtags(txt):\n",
    "    return re.sub(r'#','',txt)\n",
    "\n",
    "def removeRetweet(txt):\n",
    "    return re.sub(r'RT[\\s]+','',txt)\n",
    "\n",
    "def removeHyperlinks(txt):\n",
    "    return re.sub(r'https?:\\/\\/\\S+','',txt)\n",
    "\n",
    "def removePunctuations(txt):\n",
    "    txt  = \"\".join([char for char in txt if char not in string.punctuation])\n",
    "    txt = re.sub('[0-9]+', '', txt)\n",
    "    return txt\n",
    "\n",
    "def txtVerarbeitung(txt):\n",
    "    txt = removeEmojis(txt)\n",
    "    txt = removeMentions(txt)\n",
    "    txt = removeHashtags(txt)\n",
    "    txt = removeRetweet(txt)\n",
    "    txt = removeHyperlinks(txt)\n",
    "    txt = removePunctuations(txt)\n",
    "    return txt\n",
    "\n",
    "def tokenization(txt):\n",
    "    txt = re.split('\\W+', txt)\n",
    "    return txt\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('german')\n",
    "def removeStopwords(txt):\n",
    "    txt = [word for word in txt if word not in stopword]\n",
    "    return txt\n",
    "\n",
    "hannover = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "def lemmatizer(txt):\n",
    "    lemmatized = []\n",
    "    for word in txt:\n",
    "        if word and word.strip():\n",
    "            result = hannover.analyze(word)[0]\n",
    "            lemmatized.append(result)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heute_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0     Mal eine Frage\\nIst das heute die Ruhe vor od...   \n1    unterwegs   Alles gut  blockchainopfer war ich...   \n2     Heute sind die Grundrechte  Tage in Haft Es d...   \n3                                      Läuft heute BVB   \n4                    Also  hat Bock heute\\n\\n\\n BVBBMG   \n..                                                 ...   \n495    Mia Daniels und die praktische Führerscheinp...   \n496  iMTV Guuude \\nheute ist der letzte Warmup Qual...   \n497  th Servicetweet DiscoursMaschine Corona Querde...   \n498  Mir gehts heute nicht gut Entfolgt an einem an...   \n499   Obwohl sich die Anschuldigung des ARDMagazins...   \n\n                                       Tweet_tokenized  \\\n0    [, mal, eine, frage, ist, das, heute, die, ruh...   \n1    [unterwegs, alles, gut, blockchainopfer, war, ...   \n2    [, heute, sind, die, grundrechte, tage, in, ha...   \n3                                  [läuft, heute, bvb]   \n4                     [also, hat, bock, heute, bvbbmg]   \n..                                                 ...   \n495  [, mia, daniels, und, die, praktische, führers...   \n496  [imtv, guuude, heute, ist, der, letzte, warmup...   \n497  [th, servicetweet, discoursmaschine, corona, q...   \n498  [mir, gehts, heute, nicht, gut, entfolgt, an, ...   \n499  [, obwohl, sich, die, anschuldigung, des, ardm...   \n\n                                         Tweet_nonstop  \\\n0                   [, mal, frage, heute, ruhe, sturm]   \n1    [unterwegs, gut, blockchainopfer, schon, wurde...   \n2    [, heute, grundrechte, tage, haft, darf, verge...   \n3                                  [läuft, heute, bvb]   \n4                                [bock, heute, bvbbmg]   \n..                                                 ...   \n495  [, mia, daniels, praktische, führerscheinprüfu...   \n496  [imtv, guuude, heute, letzte, warmup, qualifie...   \n497  [th, servicetweet, discoursmaschine, corona, q...   \n498                 [gehts, heute, gut, entfolgt, tag]   \n499  [, obwohl, anschuldigung, ardmagazins, panoram...   \n\n                                      Tweet_lemmatized  \n0                     [mal, Frage, heute, Ruhe, Sturm]  \n1    [unterwegs, gut, Blockchainopfer, schon, werde...  \n2    [heute, Grundrecht, Tag, Haft, dürfen, Vergess...  \n3                                 [laufen, heute, Bvb]  \n4                                [Bock, heute, Bvbbmg]  \n..                                                 ...  \n495  [Mia, Daniel, praktisch, Führerscheinprüfung, ...  \n496  [Imtv, Guuude, heute, letzter, Warmup, Qualifi...  \n497  [th, Servicetweet, Discoursmaschine, Corona, Q...  \n498                [gehts, heute, gut, entfolgen, Tag]  \n499  [obwohl, Anschuldigung, Ardmagazins, Panorama,...  \n\n[500 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mal eine Frage\\nIst das heute die Ruhe vor od...</td>\n      <td>[, mal, eine, frage, ist, das, heute, die, ruh...</td>\n      <td>[, mal, frage, heute, ruhe, sturm]</td>\n      <td>[mal, Frage, heute, Ruhe, Sturm]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>unterwegs   Alles gut  blockchainopfer war ich...</td>\n      <td>[unterwegs, alles, gut, blockchainopfer, war, ...</td>\n      <td>[unterwegs, gut, blockchainopfer, schon, wurde...</td>\n      <td>[unterwegs, gut, Blockchainopfer, schon, werde...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heute sind die Grundrechte  Tage in Haft Es d...</td>\n      <td>[, heute, sind, die, grundrechte, tage, in, ha...</td>\n      <td>[, heute, grundrechte, tage, haft, darf, verge...</td>\n      <td>[heute, Grundrecht, Tag, Haft, dürfen, Vergess...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Läuft heute BVB</td>\n      <td>[läuft, heute, bvb]</td>\n      <td>[läuft, heute, bvb]</td>\n      <td>[laufen, heute, Bvb]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also  hat Bock heute\\n\\n\\n BVBBMG</td>\n      <td>[also, hat, bock, heute, bvbbmg]</td>\n      <td>[bock, heute, bvbbmg]</td>\n      <td>[Bock, heute, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Mia Daniels und die praktische Führerscheinp...</td>\n      <td>[, mia, daniels, und, die, praktische, führers...</td>\n      <td>[, mia, daniels, praktische, führerscheinprüfu...</td>\n      <td>[Mia, Daniel, praktisch, Führerscheinprüfung, ...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>iMTV Guuude \\nheute ist der letzte Warmup Qual...</td>\n      <td>[imtv, guuude, heute, ist, der, letzte, warmup...</td>\n      <td>[imtv, guuude, heute, letzte, warmup, qualifie...</td>\n      <td>[Imtv, Guuude, heute, letzter, Warmup, Qualifi...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>th Servicetweet DiscoursMaschine Corona Querde...</td>\n      <td>[th, servicetweet, discoursmaschine, corona, q...</td>\n      <td>[th, servicetweet, discoursmaschine, corona, q...</td>\n      <td>[th, Servicetweet, Discoursmaschine, Corona, Q...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Mir gehts heute nicht gut Entfolgt an einem an...</td>\n      <td>[mir, gehts, heute, nicht, gut, entfolgt, an, ...</td>\n      <td>[gehts, heute, gut, entfolgt, tag]</td>\n      <td>[gehts, heute, gut, entfolgen, Tag]</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Obwohl sich die Anschuldigung des ARDMagazins...</td>\n      <td>[, obwohl, sich, die, anschuldigung, des, ardm...</td>\n      <td>[, obwohl, anschuldigung, ardmagazins, panoram...</td>\n      <td>[obwohl, Anschuldigung, Ardmagazins, Panorama,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danke-Merkel_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0                                         Danke Merkel   \n1    these    DE   Und bitte nicht vergessen wer si...   \n2                                         Danke merkel   \n3     saar   Das vergessen Leute gerne\\nIn  Jahren ...   \n4    NTV wieder voll auf Grünkirs in D Waffen in si...   \n..                                                 ...   \n275   Ja endlich Hillary Clinton wollte diesen Krie...   \n276    Die  Merkel CDU ist völlig nach links abgedr...   \n277               Danke Merkel  Regierung für Nichts     \n278          Danke Merkel kann man ja nicht mehr sagen   \n279    Und wann kommt ein Argument das Sinn macht I...   \n\n                                       Tweet_tokenized  \\\n0                                    [, danke, merkel]   \n1    [these, de, und, bitte, nicht, vergessen, wer,...   \n2                                    [, danke, merkel]   \n3    [, saar, das, vergessen, leute, gerne, in, jah...   \n4    [ntv, wieder, voll, auf, grünkirs, in, d, waff...   \n..                                                 ...   \n275  [, ja, endlich, hillary, clinton, wollte, dies...   \n276  [, die, merkel, cdu, ist, völlig, nach, links,...   \n277          [danke, merkel, regierung, für, nichts, ]   \n278  [, danke, merkel, kann, man, ja, nicht, mehr, ...   \n279  [, und, wann, kommt, ein, argument, das, sinn,...   \n\n                                         Tweet_nonstop  \\\n0                                    [, danke, merkel]   \n1    [these, de, bitte, vergessen, wer, amt, gehiev...   \n2                                    [, danke, merkel]   \n3    [, saar, vergessen, leute, gerne, jahren, merk...   \n4    [ntv, voll, grünkirs, d, waffen, persönlichen,...   \n..                                                 ...   \n275  [, ja, endlich, hillary, clinton, krieg, ja, s...   \n276  [, merkel, cdu, völlig, links, abgedriftet, zb...   \n277                       [danke, merkel, regierung, ]   \n278                 [, danke, merkel, ja, mehr, sagen]   \n279  [, wann, kommt, argument, sinn, macht, blutdru...   \n\n                                      Tweet_lemmatized  \n0                                     [danken, Merkel]  \n1    [These, De, bitte, Vergessen, wer, Amt, hieven...  \n2                                     [danken, Merkel]  \n3    [Saar, Vergessen, Leute, gerne, Jahr, Merkel, ...  \n4    [Ntv, voll, Grünkirs, d, Waffe, persönlich, Ve...  \n..                                                 ...  \n275  [ja, endlich, Hillary, Clinton, Krieg, ja, sch...  \n276  [Merkel, Cdu, völlig, links, abgedriftet, Z, R...  \n277                        [danken, Merkel, Regierung]  \n278                  [danken, Merkel, ja, mehr, sagen]  \n279  [wann, kommen, Argument, Sinn, machen, Blutdru...  \n\n[280 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Danke Merkel</td>\n      <td>[, danke, merkel]</td>\n      <td>[, danke, merkel]</td>\n      <td>[danken, Merkel]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>these    DE   Und bitte nicht vergessen wer si...</td>\n      <td>[these, de, und, bitte, nicht, vergessen, wer,...</td>\n      <td>[these, de, bitte, vergessen, wer, amt, gehiev...</td>\n      <td>[These, De, bitte, Vergessen, wer, Amt, hieven...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Danke merkel</td>\n      <td>[, danke, merkel]</td>\n      <td>[, danke, merkel]</td>\n      <td>[danken, Merkel]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>saar   Das vergessen Leute gerne\\nIn  Jahren ...</td>\n      <td>[, saar, das, vergessen, leute, gerne, in, jah...</td>\n      <td>[, saar, vergessen, leute, gerne, jahren, merk...</td>\n      <td>[Saar, Vergessen, Leute, gerne, Jahr, Merkel, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NTV wieder voll auf Grünkirs in D Waffen in si...</td>\n      <td>[ntv, wieder, voll, auf, grünkirs, in, d, waff...</td>\n      <td>[ntv, voll, grünkirs, d, waffen, persönlichen,...</td>\n      <td>[Ntv, voll, Grünkirs, d, Waffe, persönlich, Ve...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>Ja endlich Hillary Clinton wollte diesen Krie...</td>\n      <td>[, ja, endlich, hillary, clinton, wollte, dies...</td>\n      <td>[, ja, endlich, hillary, clinton, krieg, ja, s...</td>\n      <td>[ja, endlich, Hillary, Clinton, Krieg, ja, sch...</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>Die  Merkel CDU ist völlig nach links abgedr...</td>\n      <td>[, die, merkel, cdu, ist, völlig, nach, links,...</td>\n      <td>[, merkel, cdu, völlig, links, abgedriftet, zb...</td>\n      <td>[Merkel, Cdu, völlig, links, abgedriftet, Z, R...</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>Danke Merkel  Regierung für Nichts</td>\n      <td>[danke, merkel, regierung, für, nichts, ]</td>\n      <td>[danke, merkel, regierung, ]</td>\n      <td>[danken, Merkel, Regierung]</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>Danke Merkel kann man ja nicht mehr sagen</td>\n      <td>[, danke, merkel, kann, man, ja, nicht, mehr, ...</td>\n      <td>[, danke, merkel, ja, mehr, sagen]</td>\n      <td>[danken, Merkel, ja, mehr, sagen]</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>Und wann kommt ein Argument das Sinn macht I...</td>\n      <td>[, und, wann, kommt, ein, argument, das, sinn,...</td>\n      <td>[, wann, kommt, argument, sinn, macht, blutdru...</td>\n      <td>[wann, kommen, Argument, Sinn, machen, Blutdru...</td>\n    </tr>\n  </tbody>\n</table>\n<p>280 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fresse_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0      Was in Kanada passiert ist weltweit geplant ...   \n1               Lauterbach Halt endlich mal die Fresse   \n2    Dehnungsstreifen sind voll schön  und Haare am...   \n3                 Meine Fresse geht das einfach BVBBMG   \n4    JAAAAA MAN VERDAMMTE SCHEIßE\\n\\nMEINE FRESSE E...   \n..                                                 ...   \n495                              bitte halt die fresse   \n496   Soooooo geht es zig Familien Wir wollen ja sc...   \n497   DAS GESUNDHEITSSYSTEM WAR NIE ÜBERLASTET\\n\\nJ...   \n498  Wu Wenn du für Hackepeter im Kopf und das Rech...   \n499    Soeder wenn er was gegen Fake News tun will ...   \n\n                                       Tweet_tokenized  \\\n0    [, was, in, kanada, passiert, ist, weltweit, g...   \n1        [lauterbach, halt, endlich, mal, die, fresse]   \n2    [dehnungsstreifen, sind, voll, schön, und, haa...   \n3          [meine, fresse, geht, das, einfach, bvbbmg]   \n4    [jaaaaa, man, verdammte, scheiße, meine, fress...   \n..                                                 ...   \n495                       [, bitte, halt, die, fresse]   \n496  [, soooooo, geht, es, zig, familien, wir, woll...   \n497  [, das, gesundheitssystem, war, nie, überlaste...   \n498  [wu, wenn, du, für, hackepeter, im, kopf, und,...   \n499  [, soeder, wenn, er, was, gegen, fake, news, t...   \n\n                                         Tweet_nonstop  \\\n0    [, kanada, passiert, weltweit, geplant, beobac...   \n1             [lauterbach, halt, endlich, mal, fresse]   \n2    [dehnungsstreifen, voll, schön, haare, körper,...   \n3                      [fresse, geht, einfach, bvbbmg]   \n4     [jaaaaa, verdammte, scheiße, fresse, ey, bvbbmg]   \n..                                                 ...   \n495                            [, bitte, halt, fresse]   \n496  [, soooooo, geht, zig, familien, ja, schon, ga...   \n497  [, gesundheitssystem, nie, überlastet, ja, maß...   \n498  [wu, hackepeter, kopf, recht, ansteckung, demo...   \n499  [, soeder, fake, news, tun, te, fresse, halten...   \n\n                                      Tweet_lemmatized  \n0    [Kanada, passieren, weltweit, planen, beobacht...  \n1            [Lauterbach, Halt, endlich, mal, fressen]  \n2    [Dehnungsstreifen, voll, schön, Haar, Körper, ...  \n3                    [fressen, gehen, einfach, Bvbbmg]  \n4    [Jaaaaa, verdammen, Scheiße, fressen, ey, Bvbbmg]  \n..                                                 ...  \n495                             [bitte, Halt, fressen]  \n496  [Soooooo, gehen, Zig, Familie, ja, schon, gar,...  \n497  [Gesundheitssystem, nie, überlasten, ja, Maßna...  \n498  [Wu, Hackepeter, Kopf, Recht, Ansteckung, demo...  \n499  [Soeder, Fake, New, Tun, te, fressen, halten, ...  \n\n[500 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Was in Kanada passiert ist weltweit geplant ...</td>\n      <td>[, was, in, kanada, passiert, ist, weltweit, g...</td>\n      <td>[, kanada, passiert, weltweit, geplant, beobac...</td>\n      <td>[Kanada, passieren, weltweit, planen, beobacht...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lauterbach Halt endlich mal die Fresse</td>\n      <td>[lauterbach, halt, endlich, mal, die, fresse]</td>\n      <td>[lauterbach, halt, endlich, mal, fresse]</td>\n      <td>[Lauterbach, Halt, endlich, mal, fressen]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dehnungsstreifen sind voll schön  und Haare am...</td>\n      <td>[dehnungsstreifen, sind, voll, schön, und, haa...</td>\n      <td>[dehnungsstreifen, voll, schön, haare, körper,...</td>\n      <td>[Dehnungsstreifen, voll, schön, Haar, Körper, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Meine Fresse geht das einfach BVBBMG</td>\n      <td>[meine, fresse, geht, das, einfach, bvbbmg]</td>\n      <td>[fresse, geht, einfach, bvbbmg]</td>\n      <td>[fressen, gehen, einfach, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JAAAAA MAN VERDAMMTE SCHEIßE\\n\\nMEINE FRESSE E...</td>\n      <td>[jaaaaa, man, verdammte, scheiße, meine, fress...</td>\n      <td>[jaaaaa, verdammte, scheiße, fresse, ey, bvbbmg]</td>\n      <td>[Jaaaaa, verdammen, Scheiße, fressen, ey, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>bitte halt die fresse</td>\n      <td>[, bitte, halt, die, fresse]</td>\n      <td>[, bitte, halt, fresse]</td>\n      <td>[bitte, Halt, fressen]</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>Soooooo geht es zig Familien Wir wollen ja sc...</td>\n      <td>[, soooooo, geht, es, zig, familien, wir, woll...</td>\n      <td>[, soooooo, geht, zig, familien, ja, schon, ga...</td>\n      <td>[Soooooo, gehen, Zig, Familie, ja, schon, gar,...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>DAS GESUNDHEITSSYSTEM WAR NIE ÜBERLASTET\\n\\nJ...</td>\n      <td>[, das, gesundheitssystem, war, nie, überlaste...</td>\n      <td>[, gesundheitssystem, nie, überlastet, ja, maß...</td>\n      <td>[Gesundheitssystem, nie, überlasten, ja, Maßna...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Wu Wenn du für Hackepeter im Kopf und das Rech...</td>\n      <td>[wu, wenn, du, für, hackepeter, im, kopf, und,...</td>\n      <td>[wu, hackepeter, kopf, recht, ansteckung, demo...</td>\n      <td>[Wu, Hackepeter, Kopf, Recht, Ansteckung, demo...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Soeder wenn er was gegen Fake News tun will ...</td>\n      <td>[, soeder, wenn, er, was, gegen, fake, news, t...</td>\n      <td>[, soeder, fake, news, tun, te, fresse, halten...</td>\n      <td>[Soeder, Fake, New, Tun, te, fressen, halten, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generateCleanedOutput(csvFileName, outputFileName):\n",
    "    df = pd.DataFrame(pd.read_csv(csvFileName), columns=['Tweet'])\n",
    "    df['Tweet'] = df['Tweet'].apply(txtVerarbeitung)\n",
    "    df['Tweet_tokenized'] = df['Tweet'].apply(lambda x: tokenization(x.lower()))\n",
    "    df['Tweet_nonstop'] = df['Tweet_tokenized'].apply(removeStopwords)\n",
    "    df['Tweet_lemmatized'] = df['Tweet_nonstop'].apply(lemmatizer)\n",
    "    print(csvFileName)\n",
    "    display(df)\n",
    "    df['Tweet_lemmatized'].apply(lambda s: ' '.join([str(elem) for elem in s])).to_csv(outputFileName)\n",
    "\n",
    "# Heute Tweets\n",
    "generateCleanedOutput('heute_tweets.csv', 'heute_tweets_Vorverarbeitung.csv')\n",
    "\n",
    "# Danke Merkel Tweets\n",
    "generateCleanedOutput('danke-Merkel_tweets.csv', 'danke-Merkel_tweets_Vorverarbeitung.csv')\n",
    "\n",
    "# Fresse Tweets\n",
    "generateCleanedOutput('Fresse_tweets.csv', 'Fresse_tweets_Vorverarbeitung.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}