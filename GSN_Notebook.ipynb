{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/galal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from IPython.core.display_functions import display\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from HanTa import HanoverTagger as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnauthorized\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweet\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     21\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m tweets:\n\u001B[1;32m     24\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend([tweet\u001B[38;5;241m.\u001B[39mfull_text])\n\u001B[1;32m     26\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(data, columns\u001B[38;5;241m=\u001B[39mcolumns)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:86\u001B[0m, in \u001B[0;36mBaseIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:286\u001B[0m, in \u001B[0;36mItemIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_index \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Reached end of current page, get the next page...\u001B[39;00m\n\u001B[0;32m--> 286\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    288\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_iterator)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:86\u001B[0m, in \u001B[0;36mBaseIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:167\u001B[0m, in \u001B[0;36mIdIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 167\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRawParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m     model \u001B[38;5;241m=\u001B[39m ModelParser()\u001B[38;5;241m.\u001B[39mparse(\n\u001B[1;32m    170\u001B[0m         data, api \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[1;32m    171\u001B[0m         payload_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_list,\n\u001B[1;32m    172\u001B[0m         payload_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_type\n\u001B[1;32m    173\u001B[0m     )\n\u001B[1;32m    174\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mparser\u001B[38;5;241m.\u001B[39mparse(\n\u001B[1;32m    175\u001B[0m         data, api \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[1;32m    176\u001B[0m         payload_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_list,\n\u001B[1;32m    177\u001B[0m         payload_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_type\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:33\u001B[0m, in \u001B[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(method)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:46\u001B[0m, in \u001B[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     44\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_list\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_list\n\u001B[1;32m     45\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_type\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_type\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:1268\u001B[0m, in \u001B[0;36mAPI.search_tweets\u001B[0;34m(self, q, **kwargs)\u001B[0m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;129m@pagination\u001B[39m(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;129m@payload\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msearch_results\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msearch_tweets\u001B[39m(\u001B[38;5;28mself\u001B[39m, q, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1194\u001B[0m     \u001B[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001B[39;00m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;124;03m                     until, since_id, max_id, include_entities)\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1266\u001B[0m \u001B[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets\u001B[39;00m\n\u001B[1;32m   1267\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msearch/tweets\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint_parameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mq\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeocode\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlang\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocale\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresult_type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcount\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muntil\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msince_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minclude_entities\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:257\u001B[0m, in \u001B[0;36mAPI.request\u001B[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadRequest(resp)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m401\u001B[39m:\n\u001B[0;32m--> 257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Unauthorized(resp)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m403\u001B[39m:\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Forbidden(resp)\n",
      "\u001B[0;31mUnauthorized\u001B[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "api_key = 'ALR6ExjYkMBfebl33tcjXyZ4s'\n",
    "api_key_secret = 'nDDTt61clONQ8isJifsLT7nqhxfjHFFlo6W8rl2SblhPMeVLk3'\n",
    "\n",
    "access_token = '2317868736-6BMg18lkng6EIY2nrSSoISburY9QcaUovk78xPY'\n",
    "access_token_secret = 'UcHtfXjvurM4dT9ZpMgvwDfZ2ukQtEGQqaLEfhueSeFyq'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "limit=500\n",
    "\n",
    "keywords = '#HaltDieFresse'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#HaltDieFresse_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = '#heute'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#heute_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = '#DankeMerkel'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#DankeMerkel_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'Fresse'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('Fresse_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'heute'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('heute_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'danke Merkel'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('danke-Merkel_tweets.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vorverarbeitung von  txt\n",
    "def removeEmojis(txt):\n",
    "     regrex_pattern = re.compile(pattern = \"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "     return regrex_pattern.sub(r'',txt)\n",
    "\n",
    "def removeMentions(txt):\n",
    "    return re.sub(r'@[A-Za-z0-9]+', '' ,txt)\n",
    "\n",
    "def removeHashtags(txt):\n",
    "    return re.sub(r'#','',txt)\n",
    "\n",
    "def removeRetweet(txt):\n",
    "    return re.sub(r'RT[\\s]+','',txt)\n",
    "\n",
    "def removeHyperlinks(txt):\n",
    "    return re.sub(r'https?:\\/\\/\\S+','',txt)\n",
    "\n",
    "def removePunctuations(txt):\n",
    "    txt  = \"\".join([char for char in txt if char not in string.punctuation])\n",
    "    txt = re.sub('[0-9]+', '', txt)\n",
    "    return txt\n",
    "\n",
    "def txtVerarbeitung(txt):\n",
    "    txt = removeEmojis(txt)\n",
    "    txt = removeMentions(txt)\n",
    "    txt = removeHashtags(txt)\n",
    "    txt = removeRetweet(txt)\n",
    "    txt = removeHyperlinks(txt)\n",
    "    txt = removePunctuations(txt)\n",
    "    return txt\n",
    "\n",
    "def tokenization(txt):\n",
    "    txt = re.split('\\W+', txt)\n",
    "    return txt\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('german')\n",
    "def removeStopwords(txt):\n",
    "    txt = [word for word in txt if word not in stopword]\n",
    "    return txt\n",
    "\n",
    "hannover = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "def lemmatizer(txt):\n",
    "    lemmatized = []\n",
    "    for word in txt:\n",
    "        if word and word.strip():\n",
    "            result = hannover.analyze(word)[0]\n",
    "            lemmatized.append(result)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heute_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0     Mal eine Frage\\nIst das heute die Ruhe vor od...   \n1    unterwegs   Alles gut  blockchainopfer war ich...   \n2     Heute sind die Grundrechte  Tage in Haft Es d...   \n3                                      Läuft heute BVB   \n4                    Also  hat Bock heute\\n\\n\\n BVBBMG   \n..                                                 ...   \n495    Mia Daniels und die praktische Führerscheinp...   \n496  iMTV Guuude \\nheute ist der letzte Warmup Qual...   \n497  th Servicetweet DiscoursMaschine Corona Querde...   \n498  Mir gehts heute nicht gut Entfolgt an einem an...   \n499   Obwohl sich die Anschuldigung des ARDMagazins...   \n\n                                       Tweet_tokenized  \\\n0    [, mal, eine, frage, ist, das, heute, die, ruh...   \n1    [unterwegs, alles, gut, blockchainopfer, war, ...   \n2    [, heute, sind, die, grundrechte, tage, in, ha...   \n3                                  [läuft, heute, bvb]   \n4                     [also, hat, bock, heute, bvbbmg]   \n..                                                 ...   \n495  [, mia, daniels, und, die, praktische, führers...   \n496  [imtv, guuude, heute, ist, der, letzte, warmup...   \n497  [th, servicetweet, discoursmaschine, corona, q...   \n498  [mir, gehts, heute, nicht, gut, entfolgt, an, ...   \n499  [, obwohl, sich, die, anschuldigung, des, ardm...   \n\n                                         Tweet_nonstop  \\\n0                   [, mal, frage, heute, ruhe, sturm]   \n1    [unterwegs, gut, blockchainopfer, schon, wurde...   \n2    [, heute, grundrechte, tage, haft, darf, verge...   \n3                                  [läuft, heute, bvb]   \n4                                [bock, heute, bvbbmg]   \n..                                                 ...   \n495  [, mia, daniels, praktische, führerscheinprüfu...   \n496  [imtv, guuude, heute, letzte, warmup, qualifie...   \n497  [th, servicetweet, discoursmaschine, corona, q...   \n498                 [gehts, heute, gut, entfolgt, tag]   \n499  [, obwohl, anschuldigung, ardmagazins, panoram...   \n\n                                      Tweet_lemmatized  \n0                     [mal, Frage, heute, Ruhe, Sturm]  \n1    [unterwegs, gut, Blockchainopfer, schon, werde...  \n2    [heute, Grundrecht, Tag, Haft, dürfen, Vergess...  \n3                                 [laufen, heute, Bvb]  \n4                                [Bock, heute, Bvbbmg]  \n..                                                 ...  \n495  [Mia, Daniel, praktisch, Führerscheinprüfung, ...  \n496  [Imtv, Guuude, heute, letzter, Warmup, Qualifi...  \n497  [th, Servicetweet, Discoursmaschine, Corona, Q...  \n498                [gehts, heute, gut, entfolgen, Tag]  \n499  [obwohl, Anschuldigung, Ardmagazins, Panorama,...  \n\n[500 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mal eine Frage\\nIst das heute die Ruhe vor od...</td>\n      <td>[, mal, eine, frage, ist, das, heute, die, ruh...</td>\n      <td>[, mal, frage, heute, ruhe, sturm]</td>\n      <td>[mal, Frage, heute, Ruhe, Sturm]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>unterwegs   Alles gut  blockchainopfer war ich...</td>\n      <td>[unterwegs, alles, gut, blockchainopfer, war, ...</td>\n      <td>[unterwegs, gut, blockchainopfer, schon, wurde...</td>\n      <td>[unterwegs, gut, Blockchainopfer, schon, werde...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heute sind die Grundrechte  Tage in Haft Es d...</td>\n      <td>[, heute, sind, die, grundrechte, tage, in, ha...</td>\n      <td>[, heute, grundrechte, tage, haft, darf, verge...</td>\n      <td>[heute, Grundrecht, Tag, Haft, dürfen, Vergess...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Läuft heute BVB</td>\n      <td>[läuft, heute, bvb]</td>\n      <td>[läuft, heute, bvb]</td>\n      <td>[laufen, heute, Bvb]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also  hat Bock heute\\n\\n\\n BVBBMG</td>\n      <td>[also, hat, bock, heute, bvbbmg]</td>\n      <td>[bock, heute, bvbbmg]</td>\n      <td>[Bock, heute, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Mia Daniels und die praktische Führerscheinp...</td>\n      <td>[, mia, daniels, und, die, praktische, führers...</td>\n      <td>[, mia, daniels, praktische, führerscheinprüfu...</td>\n      <td>[Mia, Daniel, praktisch, Führerscheinprüfung, ...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>iMTV Guuude \\nheute ist der letzte Warmup Qual...</td>\n      <td>[imtv, guuude, heute, ist, der, letzte, warmup...</td>\n      <td>[imtv, guuude, heute, letzte, warmup, qualifie...</td>\n      <td>[Imtv, Guuude, heute, letzter, Warmup, Qualifi...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>th Servicetweet DiscoursMaschine Corona Querde...</td>\n      <td>[th, servicetweet, discoursmaschine, corona, q...</td>\n      <td>[th, servicetweet, discoursmaschine, corona, q...</td>\n      <td>[th, Servicetweet, Discoursmaschine, Corona, Q...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Mir gehts heute nicht gut Entfolgt an einem an...</td>\n      <td>[mir, gehts, heute, nicht, gut, entfolgt, an, ...</td>\n      <td>[gehts, heute, gut, entfolgt, tag]</td>\n      <td>[gehts, heute, gut, entfolgen, Tag]</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Obwohl sich die Anschuldigung des ARDMagazins...</td>\n      <td>[, obwohl, sich, die, anschuldigung, des, ardm...</td>\n      <td>[, obwohl, anschuldigung, ardmagazins, panoram...</td>\n      <td>[obwohl, Anschuldigung, Ardmagazins, Panorama,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#heute_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0    Teterower See\\n\\naktuell heute see schilf tete...   \n1                            Auto Ankauf heute Sofort    \n2    ZDFChinaReporter UlfRöller um  bei heute kriti...   \n3    TKS Gedenkkundgebung in Potsdam an den rechten...   \n4                     Auto Ankauf heute Sofort Bargeld   \n..                                                 ...   \n349  In my opinion SPSCHWEIZ DEFINES the term RETAR...   \n350  q qanon stasi Easterling SPY\\n\\nWeAreNATO worl...   \n351  Heute Mensch und ich haben bis  Uhr geschlafen...   \n352  Kuenstler Heute wird weltweit der PlumpuddingT...   \n353  Heute wird weltweit der PlumpuddingTag zelibri...   \n\n                                       Tweet_tokenized  \\\n0    [teterower, see, aktuell, heute, see, schilf, ...   \n1                      [auto, ankauf, heute, sofort, ]   \n2    [zdfchinareporter, ulfröller, um, bei, heute, ...   \n3    [tks, gedenkkundgebung, in, potsdam, an, den, ...   \n4               [auto, ankauf, heute, sofort, bargeld]   \n..                                                 ...   \n349  [in, my, opinion, spschweiz, defines, the, ter...   \n350  [q, qanon, stasi, easterling, spy, wearenato, ...   \n351  [heute, mensch, und, ich, haben, bis, uhr, ges...   \n352  [kuenstler, heute, wird, weltweit, der, plumpu...   \n353  [heute, wird, weltweit, der, plumpuddingtag, z...   \n\n                                         Tweet_nonstop  \\\n0    [teterower, see, aktuell, heute, see, schilf, ...   \n1                      [auto, ankauf, heute, sofort, ]   \n2    [zdfchinareporter, ulfröller, heute, kritisch,...   \n3    [tks, gedenkkundgebung, potsdam, rechten, terr...   \n4               [auto, ankauf, heute, sofort, bargeld]   \n..                                                 ...   \n349  [my, opinion, spschweiz, defines, the, term, r...   \n350  [q, qanon, stasi, easterling, spy, wearenato, ...   \n351  [heute, mensch, uhr, geschlafen, couch, überna...   \n352  [kuenstler, heute, weltweit, plumpuddingtag, z...   \n353  [heute, weltweit, plumpuddingtag, zelibriert, ...   \n\n                                      Tweet_lemmatized  \n0    [Teterower, See, aktuell, heute, See, Schilf, ...  \n1                        [Auto, Ankauf, heute, sofort]  \n2    [Zdfchinareporter, Ulfröller, heute, kritisch,...  \n3    [Tks, Gedenkkundgebung, Potsdam, Recht, Terror...  \n4               [Auto, Ankauf, heute, sofort, Bargeld]  \n..                                                 ...  \n349  [my, Opinion, Spschweiz, Defines, The, Term, R...  \n350  [q, Qanon, Stasi, Easterling, Spy, Wearenato, ...  \n351  [heute, Mensch, Uhr, schlafen, Couch, übernach...  \n352  [Kuenstler, heute, weltweit, Plumpuddingtag, z...  \n353  [heute, weltweit, Plumpuddingtag, zelibriert, ...  \n\n[354 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Teterower See\\n\\naktuell heute see schilf tete...</td>\n      <td>[teterower, see, aktuell, heute, see, schilf, ...</td>\n      <td>[teterower, see, aktuell, heute, see, schilf, ...</td>\n      <td>[Teterower, See, aktuell, heute, See, Schilf, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Auto Ankauf heute Sofort</td>\n      <td>[auto, ankauf, heute, sofort, ]</td>\n      <td>[auto, ankauf, heute, sofort, ]</td>\n      <td>[Auto, Ankauf, heute, sofort]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ZDFChinaReporter UlfRöller um  bei heute kriti...</td>\n      <td>[zdfchinareporter, ulfröller, um, bei, heute, ...</td>\n      <td>[zdfchinareporter, ulfröller, heute, kritisch,...</td>\n      <td>[Zdfchinareporter, Ulfröller, heute, kritisch,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TKS Gedenkkundgebung in Potsdam an den rechten...</td>\n      <td>[tks, gedenkkundgebung, in, potsdam, an, den, ...</td>\n      <td>[tks, gedenkkundgebung, potsdam, rechten, terr...</td>\n      <td>[Tks, Gedenkkundgebung, Potsdam, Recht, Terror...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Auto Ankauf heute Sofort Bargeld</td>\n      <td>[auto, ankauf, heute, sofort, bargeld]</td>\n      <td>[auto, ankauf, heute, sofort, bargeld]</td>\n      <td>[Auto, Ankauf, heute, sofort, Bargeld]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>In my opinion SPSCHWEIZ DEFINES the term RETAR...</td>\n      <td>[in, my, opinion, spschweiz, defines, the, ter...</td>\n      <td>[my, opinion, spschweiz, defines, the, term, r...</td>\n      <td>[my, Opinion, Spschweiz, Defines, The, Term, R...</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>q qanon stasi Easterling SPY\\n\\nWeAreNATO worl...</td>\n      <td>[q, qanon, stasi, easterling, spy, wearenato, ...</td>\n      <td>[q, qanon, stasi, easterling, spy, wearenato, ...</td>\n      <td>[q, Qanon, Stasi, Easterling, Spy, Wearenato, ...</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>Heute Mensch und ich haben bis  Uhr geschlafen...</td>\n      <td>[heute, mensch, und, ich, haben, bis, uhr, ges...</td>\n      <td>[heute, mensch, uhr, geschlafen, couch, überna...</td>\n      <td>[heute, Mensch, Uhr, schlafen, Couch, übernach...</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>Kuenstler Heute wird weltweit der PlumpuddingT...</td>\n      <td>[kuenstler, heute, wird, weltweit, der, plumpu...</td>\n      <td>[kuenstler, heute, weltweit, plumpuddingtag, z...</td>\n      <td>[Kuenstler, heute, weltweit, Plumpuddingtag, z...</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>Heute wird weltweit der PlumpuddingTag zelibri...</td>\n      <td>[heute, wird, weltweit, der, plumpuddingtag, z...</td>\n      <td>[heute, weltweit, plumpuddingtag, zelibriert, ...</td>\n      <td>[heute, weltweit, Plumpuddingtag, zelibriert, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>354 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danke-Merkel_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0                                         Danke Merkel   \n1    these    DE   Und bitte nicht vergessen wer si...   \n2                                         Danke merkel   \n3     saar   Das vergessen Leute gerne\\nIn  Jahren ...   \n4    NTV wieder voll auf Grünkirs in D Waffen in si...   \n..                                                 ...   \n275   Ja endlich Hillary Clinton wollte diesen Krie...   \n276    Die  Merkel CDU ist völlig nach links abgedr...   \n277               Danke Merkel  Regierung für Nichts     \n278          Danke Merkel kann man ja nicht mehr sagen   \n279    Und wann kommt ein Argument das Sinn macht I...   \n\n                                       Tweet_tokenized  \\\n0                                    [, danke, merkel]   \n1    [these, de, und, bitte, nicht, vergessen, wer,...   \n2                                    [, danke, merkel]   \n3    [, saar, das, vergessen, leute, gerne, in, jah...   \n4    [ntv, wieder, voll, auf, grünkirs, in, d, waff...   \n..                                                 ...   \n275  [, ja, endlich, hillary, clinton, wollte, dies...   \n276  [, die, merkel, cdu, ist, völlig, nach, links,...   \n277          [danke, merkel, regierung, für, nichts, ]   \n278  [, danke, merkel, kann, man, ja, nicht, mehr, ...   \n279  [, und, wann, kommt, ein, argument, das, sinn,...   \n\n                                         Tweet_nonstop  \\\n0                                    [, danke, merkel]   \n1    [these, de, bitte, vergessen, wer, amt, gehiev...   \n2                                    [, danke, merkel]   \n3    [, saar, vergessen, leute, gerne, jahren, merk...   \n4    [ntv, voll, grünkirs, d, waffen, persönlichen,...   \n..                                                 ...   \n275  [, ja, endlich, hillary, clinton, krieg, ja, s...   \n276  [, merkel, cdu, völlig, links, abgedriftet, zb...   \n277                       [danke, merkel, regierung, ]   \n278                 [, danke, merkel, ja, mehr, sagen]   \n279  [, wann, kommt, argument, sinn, macht, blutdru...   \n\n                                      Tweet_lemmatized  \n0                                     [danken, Merkel]  \n1    [These, De, bitte, Vergessen, wer, Amt, hieven...  \n2                                     [danken, Merkel]  \n3    [Saar, Vergessen, Leute, gerne, Jahr, Merkel, ...  \n4    [Ntv, voll, Grünkirs, d, Waffe, persönlich, Ve...  \n..                                                 ...  \n275  [ja, endlich, Hillary, Clinton, Krieg, ja, sch...  \n276  [Merkel, Cdu, völlig, links, abgedriftet, Z, R...  \n277                        [danken, Merkel, Regierung]  \n278                  [danken, Merkel, ja, mehr, sagen]  \n279  [wann, kommen, Argument, Sinn, machen, Blutdru...  \n\n[280 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Danke Merkel</td>\n      <td>[, danke, merkel]</td>\n      <td>[, danke, merkel]</td>\n      <td>[danken, Merkel]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>these    DE   Und bitte nicht vergessen wer si...</td>\n      <td>[these, de, und, bitte, nicht, vergessen, wer,...</td>\n      <td>[these, de, bitte, vergessen, wer, amt, gehiev...</td>\n      <td>[These, De, bitte, Vergessen, wer, Amt, hieven...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Danke merkel</td>\n      <td>[, danke, merkel]</td>\n      <td>[, danke, merkel]</td>\n      <td>[danken, Merkel]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>saar   Das vergessen Leute gerne\\nIn  Jahren ...</td>\n      <td>[, saar, das, vergessen, leute, gerne, in, jah...</td>\n      <td>[, saar, vergessen, leute, gerne, jahren, merk...</td>\n      <td>[Saar, Vergessen, Leute, gerne, Jahr, Merkel, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NTV wieder voll auf Grünkirs in D Waffen in si...</td>\n      <td>[ntv, wieder, voll, auf, grünkirs, in, d, waff...</td>\n      <td>[ntv, voll, grünkirs, d, waffen, persönlichen,...</td>\n      <td>[Ntv, voll, Grünkirs, d, Waffe, persönlich, Ve...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>Ja endlich Hillary Clinton wollte diesen Krie...</td>\n      <td>[, ja, endlich, hillary, clinton, wollte, dies...</td>\n      <td>[, ja, endlich, hillary, clinton, krieg, ja, s...</td>\n      <td>[ja, endlich, Hillary, Clinton, Krieg, ja, sch...</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>Die  Merkel CDU ist völlig nach links abgedr...</td>\n      <td>[, die, merkel, cdu, ist, völlig, nach, links,...</td>\n      <td>[, merkel, cdu, völlig, links, abgedriftet, zb...</td>\n      <td>[Merkel, Cdu, völlig, links, abgedriftet, Z, R...</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>Danke Merkel  Regierung für Nichts</td>\n      <td>[danke, merkel, regierung, für, nichts, ]</td>\n      <td>[danke, merkel, regierung, ]</td>\n      <td>[danken, Merkel, Regierung]</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>Danke Merkel kann man ja nicht mehr sagen</td>\n      <td>[, danke, merkel, kann, man, ja, nicht, mehr, ...</td>\n      <td>[, danke, merkel, ja, mehr, sagen]</td>\n      <td>[danken, Merkel, ja, mehr, sagen]</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>Und wann kommt ein Argument das Sinn macht I...</td>\n      <td>[, und, wann, kommt, ein, argument, das, sinn,...</td>\n      <td>[, wann, kommt, argument, sinn, macht, blutdru...</td>\n      <td>[wann, kommen, Argument, Sinn, machen, Blutdru...</td>\n    </tr>\n  </tbody>\n</table>\n<p>280 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#DankeMerkel_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                Tweet  \\\n0    ungeimpft unge simon tanzverbot haider dankem...   \n1    Letzter Tag mit Merkel Als sie ins Amt trat w...   \n2     Endlich mal ein Statement das die Mehrheit d...   \n3   FriedrichMerz Erst das dreggische Haus verlass...   \n4   Die Vorstellungen der Regierenden und ihrer Un...   \n..                                                ...   \n65                         Tja auch dafür DankeMerkel   \n66   Hm wahrscheinlich gibt es eine CDU vor und ei...   \n67  Haben grad ein rechtliches Problem mit Xanny …...   \n68   PR  Impfungen und jede Currywurst und Bier se...   \n69  PR  Impfungen und jede Currywurst und Bier sel...   \n\n                                      Tweet_tokenized  \\\n0   [, ungeimpft, unge, simon, tanzverbot, haider,...   \n1   [, letzter, tag, mit, merkel, als, sie, ins, a...   \n2   [, endlich, mal, ein, statement, das, die, meh...   \n3   [friedrichmerz, erst, das, dreggische, haus, v...   \n4   [die, vorstellungen, der, regierenden, und, ih...   \n..                                                ...   \n65                  [, tja, auch, dafür, dankemerkel]   \n66  [, hm, wahrscheinlich, gibt, es, eine, cdu, vo...   \n67  [haben, grad, ein, rechtliches, problem, mit, ...   \n68  [, pr, impfungen, und, jede, currywurst, und, ...   \n69  [pr, impfungen, und, jede, currywurst, und, bi...   \n\n                                        Tweet_nonstop  \\\n0   [, ungeimpft, unge, simon, tanzverbot, haider,...   \n1   [, letzter, tag, merkel, amt, trat, jahre, alt...   \n2   [, endlich, mal, statement, mehrheit, bürgerin...   \n3   [friedrichmerz, erst, dreggische, haus, verlas...   \n4   [vorstellungen, regierenden, unterstützer, hal...   \n..                                                ...   \n65                        [, tja, dafür, dankemerkel]   \n66  [, hm, wahrscheinlich, gibt, cdu, ära, merkel,...   \n67  [grad, rechtliches, problem, xanny, plan, rele...   \n68  [, pr, impfungen, currywurst, bier, selber, be...   \n69  [pr, impfungen, currywurst, bier, selber, beza...   \n\n                                     Tweet_lemmatized  \n0   [Ungeimpft, ung, Simon, Tanzverbot, Haider, Da...  \n1   [letzter, Tag, Merkel, Amt, treten, Jahr, alt,...  \n2   [endlich, mal, Statement, Mehrheit, Bürgerinne...  \n3   [Friedrichmerz, erst, dreggisch, Haus, verlass...  \n4   [Vorstellung, regierend, Unterstützer, Halt, a...  \n..                                                ...  \n65                          [tja, dafür, Dankemerkel]  \n66  [hm, wahrscheinlich, geben, Cdu, Ära, Merkel, ...  \n67  [Grad, rechtlich, Problem, Xanny, Plan, Releas...  \n68  [pr, Impfung, Currywurst, Bier, selber, bezahl...  \n69  [pr, Impfung, Currywurst, Bier, selber, bezahl...  \n\n[70 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ungeimpft unge simon tanzverbot haider dankem...</td>\n      <td>[, ungeimpft, unge, simon, tanzverbot, haider,...</td>\n      <td>[, ungeimpft, unge, simon, tanzverbot, haider,...</td>\n      <td>[Ungeimpft, ung, Simon, Tanzverbot, Haider, Da...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Letzter Tag mit Merkel Als sie ins Amt trat w...</td>\n      <td>[, letzter, tag, mit, merkel, als, sie, ins, a...</td>\n      <td>[, letzter, tag, merkel, amt, trat, jahre, alt...</td>\n      <td>[letzter, Tag, Merkel, Amt, treten, Jahr, alt,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Endlich mal ein Statement das die Mehrheit d...</td>\n      <td>[, endlich, mal, ein, statement, das, die, meh...</td>\n      <td>[, endlich, mal, statement, mehrheit, bürgerin...</td>\n      <td>[endlich, mal, Statement, Mehrheit, Bürgerinne...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FriedrichMerz Erst das dreggische Haus verlass...</td>\n      <td>[friedrichmerz, erst, das, dreggische, haus, v...</td>\n      <td>[friedrichmerz, erst, dreggische, haus, verlas...</td>\n      <td>[Friedrichmerz, erst, dreggisch, Haus, verlass...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Die Vorstellungen der Regierenden und ihrer Un...</td>\n      <td>[die, vorstellungen, der, regierenden, und, ih...</td>\n      <td>[vorstellungen, regierenden, unterstützer, hal...</td>\n      <td>[Vorstellung, regierend, Unterstützer, Halt, a...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>Tja auch dafür DankeMerkel</td>\n      <td>[, tja, auch, dafür, dankemerkel]</td>\n      <td>[, tja, dafür, dankemerkel]</td>\n      <td>[tja, dafür, Dankemerkel]</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>Hm wahrscheinlich gibt es eine CDU vor und ei...</td>\n      <td>[, hm, wahrscheinlich, gibt, es, eine, cdu, vo...</td>\n      <td>[, hm, wahrscheinlich, gibt, cdu, ära, merkel,...</td>\n      <td>[hm, wahrscheinlich, geben, Cdu, Ära, Merkel, ...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>Haben grad ein rechtliches Problem mit Xanny …...</td>\n      <td>[haben, grad, ein, rechtliches, problem, mit, ...</td>\n      <td>[grad, rechtliches, problem, xanny, plan, rele...</td>\n      <td>[Grad, rechtlich, Problem, Xanny, Plan, Releas...</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>PR  Impfungen und jede Currywurst und Bier se...</td>\n      <td>[, pr, impfungen, und, jede, currywurst, und, ...</td>\n      <td>[, pr, impfungen, currywurst, bier, selber, be...</td>\n      <td>[pr, Impfung, Currywurst, Bier, selber, bezahl...</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>PR  Impfungen und jede Currywurst und Bier sel...</td>\n      <td>[pr, impfungen, und, jede, currywurst, und, bi...</td>\n      <td>[pr, impfungen, currywurst, bier, selber, beza...</td>\n      <td>[pr, Impfung, Currywurst, Bier, selber, bezahl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fresse_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0      Was in Kanada passiert ist weltweit geplant ...   \n1               Lauterbach Halt endlich mal die Fresse   \n2    Dehnungsstreifen sind voll schön  und Haare am...   \n3                 Meine Fresse geht das einfach BVBBMG   \n4    JAAAAA MAN VERDAMMTE SCHEIßE\\n\\nMEINE FRESSE E...   \n..                                                 ...   \n495                              bitte halt die fresse   \n496   Soooooo geht es zig Familien Wir wollen ja sc...   \n497   DAS GESUNDHEITSSYSTEM WAR NIE ÜBERLASTET\\n\\nJ...   \n498  Wu Wenn du für Hackepeter im Kopf und das Rech...   \n499    Soeder wenn er was gegen Fake News tun will ...   \n\n                                       Tweet_tokenized  \\\n0    [, was, in, kanada, passiert, ist, weltweit, g...   \n1        [lauterbach, halt, endlich, mal, die, fresse]   \n2    [dehnungsstreifen, sind, voll, schön, und, haa...   \n3          [meine, fresse, geht, das, einfach, bvbbmg]   \n4    [jaaaaa, man, verdammte, scheiße, meine, fress...   \n..                                                 ...   \n495                       [, bitte, halt, die, fresse]   \n496  [, soooooo, geht, es, zig, familien, wir, woll...   \n497  [, das, gesundheitssystem, war, nie, überlaste...   \n498  [wu, wenn, du, für, hackepeter, im, kopf, und,...   \n499  [, soeder, wenn, er, was, gegen, fake, news, t...   \n\n                                         Tweet_nonstop  \\\n0    [, kanada, passiert, weltweit, geplant, beobac...   \n1             [lauterbach, halt, endlich, mal, fresse]   \n2    [dehnungsstreifen, voll, schön, haare, körper,...   \n3                      [fresse, geht, einfach, bvbbmg]   \n4     [jaaaaa, verdammte, scheiße, fresse, ey, bvbbmg]   \n..                                                 ...   \n495                            [, bitte, halt, fresse]   \n496  [, soooooo, geht, zig, familien, ja, schon, ga...   \n497  [, gesundheitssystem, nie, überlastet, ja, maß...   \n498  [wu, hackepeter, kopf, recht, ansteckung, demo...   \n499  [, soeder, fake, news, tun, te, fresse, halten...   \n\n                                      Tweet_lemmatized  \n0    [Kanada, passieren, weltweit, planen, beobacht...  \n1            [Lauterbach, Halt, endlich, mal, fressen]  \n2    [Dehnungsstreifen, voll, schön, Haar, Körper, ...  \n3                    [fressen, gehen, einfach, Bvbbmg]  \n4    [Jaaaaa, verdammen, Scheiße, fressen, ey, Bvbbmg]  \n..                                                 ...  \n495                             [bitte, Halt, fressen]  \n496  [Soooooo, gehen, Zig, Familie, ja, schon, gar,...  \n497  [Gesundheitssystem, nie, überlasten, ja, Maßna...  \n498  [Wu, Hackepeter, Kopf, Recht, Ansteckung, demo...  \n499  [Soeder, Fake, New, Tun, te, fressen, halten, ...  \n\n[500 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Was in Kanada passiert ist weltweit geplant ...</td>\n      <td>[, was, in, kanada, passiert, ist, weltweit, g...</td>\n      <td>[, kanada, passiert, weltweit, geplant, beobac...</td>\n      <td>[Kanada, passieren, weltweit, planen, beobacht...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lauterbach Halt endlich mal die Fresse</td>\n      <td>[lauterbach, halt, endlich, mal, die, fresse]</td>\n      <td>[lauterbach, halt, endlich, mal, fresse]</td>\n      <td>[Lauterbach, Halt, endlich, mal, fressen]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dehnungsstreifen sind voll schön  und Haare am...</td>\n      <td>[dehnungsstreifen, sind, voll, schön, und, haa...</td>\n      <td>[dehnungsstreifen, voll, schön, haare, körper,...</td>\n      <td>[Dehnungsstreifen, voll, schön, Haar, Körper, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Meine Fresse geht das einfach BVBBMG</td>\n      <td>[meine, fresse, geht, das, einfach, bvbbmg]</td>\n      <td>[fresse, geht, einfach, bvbbmg]</td>\n      <td>[fressen, gehen, einfach, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JAAAAA MAN VERDAMMTE SCHEIßE\\n\\nMEINE FRESSE E...</td>\n      <td>[jaaaaa, man, verdammte, scheiße, meine, fress...</td>\n      <td>[jaaaaa, verdammte, scheiße, fresse, ey, bvbbmg]</td>\n      <td>[Jaaaaa, verdammen, Scheiße, fressen, ey, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>bitte halt die fresse</td>\n      <td>[, bitte, halt, die, fresse]</td>\n      <td>[, bitte, halt, fresse]</td>\n      <td>[bitte, Halt, fressen]</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>Soooooo geht es zig Familien Wir wollen ja sc...</td>\n      <td>[, soooooo, geht, es, zig, familien, wir, woll...</td>\n      <td>[, soooooo, geht, zig, familien, ja, schon, ga...</td>\n      <td>[Soooooo, gehen, Zig, Familie, ja, schon, gar,...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>DAS GESUNDHEITSSYSTEM WAR NIE ÜBERLASTET\\n\\nJ...</td>\n      <td>[, das, gesundheitssystem, war, nie, überlaste...</td>\n      <td>[, gesundheitssystem, nie, überlastet, ja, maß...</td>\n      <td>[Gesundheitssystem, nie, überlasten, ja, Maßna...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Wu Wenn du für Hackepeter im Kopf und das Rech...</td>\n      <td>[wu, wenn, du, für, hackepeter, im, kopf, und,...</td>\n      <td>[wu, hackepeter, kopf, recht, ansteckung, demo...</td>\n      <td>[Wu, Hackepeter, Kopf, Recht, Ansteckung, demo...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Soeder wenn er was gegen Fake News tun will ...</td>\n      <td>[, soeder, wenn, er, was, gegen, fake, news, t...</td>\n      <td>[, soeder, fake, news, tun, te, fresse, halten...</td>\n      <td>[Soeder, Fake, New, Tun, te, fressen, halten, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HaltDieFresse_tweets.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                Tweet  \\\n0   markus wenn man keine Ahnung hat heisst man Ha...   \n1                                       HaltDieFresse   \n2                     wiebe haltdiefresse Russentroll   \n3                           Lauterbach  haltdiefresse   \n4   ratzinger  HaltDieFresse\\n\\nQuerfurzer Querden...   \n..                                                ...   \n74    Gott bist Du ein Trottel \\nHaltDieFresse Cov...   \n75                               HaltDieFresse noAfD    \n76   für pseudojüdische Rassisten völkische zioNaZ...   \n77   Siemering Habt ihr sonst noch Argumente außer...   \n78         Lang Ziemlich überheblich das ein Esote...   \n\n                                      Tweet_tokenized  \\\n0   [markus, wenn, man, keine, ahnung, hat, heisst...   \n1                                   [, haltdiefresse]   \n2               [, wiebe, haltdiefresse, russentroll]   \n3                       [, lauterbach, haltdiefresse]   \n4   [ratzinger, haltdiefresse, querfurzer, querden...   \n..                                                ...   \n74  [, gott, bist, du, ein, trottel, haltdiefresse...   \n75                           [haltdiefresse, noafd, ]   \n76  [, für, pseudojüdische, rassisten, völkische, ...   \n77  [, siemering, habt, ihr, sonst, noch, argument...   \n78  [, lang, ziemlich, überheblich, das, ein, esot...   \n\n                                        Tweet_nonstop  \\\n0   [markus, ahnung, heisst, haintz, u, verbreitet...   \n1                                   [, haltdiefresse]   \n2               [, wiebe, haltdiefresse, russentroll]   \n3                       [, lauterbach, haltdiefresse]   \n4   [ratzinger, haltdiefresse, querfurzer, querden...   \n..                                                ...   \n74  [, gott, trottel, haltdiefresse, covidiot, fck...   \n75                           [haltdiefresse, noafd, ]   \n76  [, pseudojüdische, rassisten, völkische, ziona...   \n77  [, siemering, habt, argumente, außer, haltdief...   \n78  [, lang, ziemlich, überheblich, esoteriker, ab...   \n\n                                     Tweet_lemmatized  \n0   [Markus, Ahnung, heißen, Haintz, u, verbreitet...  \n1                                     [Haltdiefresse]  \n2                 [Wiebe, Haltdiefresse, russentroll]  \n3                         [Lauterbach, Haltdiefresse]  \n4   [Ratzinger, Haltdiefresse, Querfurzer, Querden...  \n..                                                ...  \n74   [Gott, Trottel, Haltdiefresse, Covidiot, Fcknzs]  \n75                             [Haltdiefresse, Noafd]  \n76  [pseudojüdisch, Rassisten, völkisch, Zionazis,...  \n77  [Siemering, haben, Argument, außer, Haltdiefre...  \n78  [lang, ziemlich, überheblich, Esoteriker, Absc...  \n\n[79 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>markus wenn man keine Ahnung hat heisst man Ha...</td>\n      <td>[markus, wenn, man, keine, ahnung, hat, heisst...</td>\n      <td>[markus, ahnung, heisst, haintz, u, verbreitet...</td>\n      <td>[Markus, Ahnung, heißen, Haintz, u, verbreitet...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HaltDieFresse</td>\n      <td>[, haltdiefresse]</td>\n      <td>[, haltdiefresse]</td>\n      <td>[Haltdiefresse]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wiebe haltdiefresse Russentroll</td>\n      <td>[, wiebe, haltdiefresse, russentroll]</td>\n      <td>[, wiebe, haltdiefresse, russentroll]</td>\n      <td>[Wiebe, Haltdiefresse, russentroll]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lauterbach  haltdiefresse</td>\n      <td>[, lauterbach, haltdiefresse]</td>\n      <td>[, lauterbach, haltdiefresse]</td>\n      <td>[Lauterbach, Haltdiefresse]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ratzinger  HaltDieFresse\\n\\nQuerfurzer Querden...</td>\n      <td>[ratzinger, haltdiefresse, querfurzer, querden...</td>\n      <td>[ratzinger, haltdiefresse, querfurzer, querden...</td>\n      <td>[Ratzinger, Haltdiefresse, Querfurzer, Querden...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Gott bist Du ein Trottel \\nHaltDieFresse Cov...</td>\n      <td>[, gott, bist, du, ein, trottel, haltdiefresse...</td>\n      <td>[, gott, trottel, haltdiefresse, covidiot, fck...</td>\n      <td>[Gott, Trottel, Haltdiefresse, Covidiot, Fcknzs]</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>HaltDieFresse noAfD</td>\n      <td>[haltdiefresse, noafd, ]</td>\n      <td>[haltdiefresse, noafd, ]</td>\n      <td>[Haltdiefresse, Noafd]</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>für pseudojüdische Rassisten völkische zioNaZ...</td>\n      <td>[, für, pseudojüdische, rassisten, völkische, ...</td>\n      <td>[, pseudojüdische, rassisten, völkische, ziona...</td>\n      <td>[pseudojüdisch, Rassisten, völkisch, Zionazis,...</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>Siemering Habt ihr sonst noch Argumente außer...</td>\n      <td>[, siemering, habt, ihr, sonst, noch, argument...</td>\n      <td>[, siemering, habt, argumente, außer, haltdief...</td>\n      <td>[Siemering, haben, Argument, außer, Haltdiefre...</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>Lang Ziemlich überheblich das ein Esote...</td>\n      <td>[, lang, ziemlich, überheblich, das, ein, esot...</td>\n      <td>[, lang, ziemlich, überheblich, esoteriker, ab...</td>\n      <td>[lang, ziemlich, überheblich, Esoteriker, Absc...</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generateCleanedOutput(csvFileName, outputFileName):\n",
    "    df = pd.DataFrame(pd.read_csv(csvFileName), columns=['Tweet'])\n",
    "    df['Tweet'] = df['Tweet'].apply(txtVerarbeitung)\n",
    "    df['Tweet_tokenized'] = df['Tweet'].apply(lambda x: tokenization(x.lower()))\n",
    "    df['Tweet_nonstop'] = df['Tweet_tokenized'].apply(removeStopwords)\n",
    "    df['Tweet_lemmatized'] = df['Tweet_nonstop'].apply(lemmatizer)\n",
    "    print(csvFileName)\n",
    "    display(df)\n",
    "    df['Tweet_lemmatized'].apply(lambda s: ' '.join([str(elem) for elem in s])).to_csv(outputFileName)\n",
    "\n",
    "# Heute Tweets\n",
    "generateCleanedOutput('heute_tweets.csv', 'heute_tweets_Vorverarbeitung.csv')\n",
    "generateCleanedOutput('#heute_tweets.csv', '#heute_hashtag_Vorverarbeitung.csv')\n",
    "\n",
    "\n",
    "# Danke Merkel Tweets\n",
    "generateCleanedOutput('danke-Merkel_tweets.csv', 'danke-Merkel_tweets_Vorverarbeitung.csv')\n",
    "generateCleanedOutput('#DankeMerkel_tweets.csv', '#DankeMerkel_hashtag_Vorverarbeitung.csv')\n",
    "\n",
    "# Fresse Tweets\n",
    "generateCleanedOutput('Fresse_tweets.csv', 'Fresse_tweets_Vorverarbeitung.csv')\n",
    "generateCleanedOutput('#HaltDieFresse_tweets.csv', '#Fresse_hashtag_Vorverarbeitung.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}