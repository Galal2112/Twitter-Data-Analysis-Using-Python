{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/galal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from HanTa import HanoverTagger as ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnauthorized\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m columns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTweet\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     21\u001B[0m data \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m tweets:\n\u001B[1;32m     24\u001B[0m     data\u001B[38;5;241m.\u001B[39mappend([tweet\u001B[38;5;241m.\u001B[39mfull_text])\n\u001B[1;32m     26\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(data, columns\u001B[38;5;241m=\u001B[39mcolumns)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:86\u001B[0m, in \u001B[0;36mBaseIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:286\u001B[0m, in \u001B[0;36mItemIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_index \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Reached end of current page, get the next page...\u001B[39;00m\n\u001B[0;32m--> 286\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    288\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpage_iterator)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:86\u001B[0m, in \u001B[0;36mBaseIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/cursor.py:167\u001B[0m, in \u001B[0;36mIdIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    164\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 167\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRawParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m     model \u001B[38;5;241m=\u001B[39m ModelParser()\u001B[38;5;241m.\u001B[39mparse(\n\u001B[1;32m    170\u001B[0m         data, api \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[1;32m    171\u001B[0m         payload_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_list,\n\u001B[1;32m    172\u001B[0m         payload_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_type\n\u001B[1;32m    173\u001B[0m     )\n\u001B[1;32m    174\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mparser\u001B[38;5;241m.\u001B[39mparse(\n\u001B[1;32m    175\u001B[0m         data, api \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[1;32m    176\u001B[0m         payload_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_list,\n\u001B[1;32m    177\u001B[0m         payload_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39mpayload_type\n\u001B[1;32m    178\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:33\u001B[0m, in \u001B[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(method)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:46\u001B[0m, in \u001B[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     44\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_list\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_list\n\u001B[1;32m     45\u001B[0m kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpayload_type\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m payload_type\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:1268\u001B[0m, in \u001B[0;36mAPI.search_tweets\u001B[0;34m(self, q, **kwargs)\u001B[0m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;129m@pagination\u001B[39m(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;129m@payload\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msearch_results\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msearch_tweets\u001B[39m(\u001B[38;5;28mself\u001B[39m, q, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1194\u001B[0m     \u001B[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001B[39;00m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;124;03m                     until, since_id, max_id, include_entities)\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1266\u001B[0m \u001B[38;5;124;03m    https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets\u001B[39;00m\n\u001B[1;32m   1267\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1268\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msearch/tweets\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendpoint_parameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mq\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeocode\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlang\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlocale\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresult_type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcount\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43muntil\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msince_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minclude_entities\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/tweepy/api.py:257\u001B[0m, in \u001B[0;36mAPI.request\u001B[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m BadRequest(resp)\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m401\u001B[39m:\n\u001B[0;32m--> 257\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Unauthorized(resp)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m403\u001B[39m:\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Forbidden(resp)\n",
      "\u001B[0;31mUnauthorized\u001B[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "api_key = 'ALR6ExjYkMBfebl33tcjXyZ4s'\n",
    "api_key_secret = 'nDDTt61clONQ8isJifsLT7nqhxfjHFFlo6W8rl2SblhPMeVLk3'\n",
    "\n",
    "access_token = '2317868736-6BMg18lkng6EIY2nrSSoISburY9QcaUovk78xPY'\n",
    "access_token_secret = 'UcHtfXjvurM4dT9ZpMgvwDfZ2ukQtEGQqaLEfhueSeFyq'\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "limit=500\n",
    "\n",
    "keywords = '#HaltDieFresse'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#HaltDieFresse_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = '#heute'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#heute_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = '#DankeMerkel'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('#DankeMerkel_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'Fresse'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('Fresse_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'heute'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('heute_tweets.csv')\n",
    "\n",
    "\n",
    "\n",
    "keywords = 'danke Merkel'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keywords, count=100, tweet_mode='extended').items(limit)\n",
    "\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    data.append([tweet.full_text])\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_csv('danke-Merkel_tweets.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 Tweet\n0    RT @derVossi_: Mal eine Frage:\\nIst das heute ...\n1    @Rosi_unterwegs @HelenaPiks @skypromusic Alles...\n2    RT @LibertyLucas26: Heute sind die Grundrechte...\n3                                     Läuft heute #BVB\n4       Also @woodyinho hat Bock heute\\n\\n🖤💛\\n #BVBBMG\n..                                                 ...\n495  RT @kartenkaro: [https://t.co/G152H8Imlf💛] Mia...\n496  RT @Noobs_iMTV: Guuude \\nheute ist der letzte ...\n497  RT @subversive_th: #Servicetweet Discours-Masc...\n498  Mir geht's heute nicht gut. Entfolgt an einem ...\n499  RT @LotharNawrath: 'Obwohl sich die Anschuldig...\n\n[500 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RT @derVossi_: Mal eine Frage:\\nIst das heute ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@Rosi_unterwegs @HelenaPiks @skypromusic Alles...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RT @LibertyLucas26: Heute sind die Grundrechte...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Läuft heute #BVB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also @woodyinho hat Bock heute\\n\\n🖤💛\\n #BVBBMG</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>RT @kartenkaro: [https://t.co/G152H8Imlf💛] Mia...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>RT @Noobs_iMTV: Guuude \\nheute ist der letzte ...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>RT @subversive_th: #Servicetweet Discours-Masc...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Mir geht's heute nicht gut. Entfolgt an einem ...</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>RT @LotharNawrath: 'Obwohl sich die Anschuldig...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv('heute_tweets.csv'), columns=['Tweet'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 Tweet  \\\n0     Mal eine Frage\\nIst das heute die Ruhe vor od...   \n1    unterwegs   Alles gut  blockchainopfer war ich...   \n2     Heute sind die Grundrechte  Tage in Haft Es d...   \n3                                      Läuft heute BVB   \n4                    Also  hat Bock heute\\n\\n\\n BVBBMG   \n..                                                 ...   \n495    Mia Daniels und die praktische Führerscheinp...   \n496  iMTV Guuude \\nheute ist der letzte Warmup Qual...   \n497  th Servicetweet DiscoursMaschine Corona Querde...   \n498  Mir gehts heute nicht gut Entfolgt an einem an...   \n499   Obwohl sich die Anschuldigung des ARDMagazins...   \n\n                                       Tweet_tokenized  \\\n0    [, mal, eine, frage, ist, das, heute, die, ruh...   \n1    [unterwegs, alles, gut, blockchainopfer, war, ...   \n2    [, heute, sind, die, grundrechte, tage, in, ha...   \n3                                  [läuft, heute, bvb]   \n4                     [also, hat, bock, heute, bvbbmg]   \n..                                                 ...   \n495  [, mia, daniels, und, die, praktische, führers...   \n496  [imtv, guuude, heute, ist, der, letzte, warmup...   \n497  [th, servicetweet, discoursmaschine, corona, q...   \n498  [mir, gehts, heute, nicht, gut, entfolgt, an, ...   \n499  [, obwohl, sich, die, anschuldigung, des, ardm...   \n\n                                         Tweet_nonstop  \\\n0                   [, mal, frage, heute, ruhe, sturm]   \n1    [unterwegs, gut, blockchainopfer, schon, wurde...   \n2    [, heute, grundrechte, tage, haft, darf, verge...   \n3                                  [läuft, heute, bvb]   \n4                                [bock, heute, bvbbmg]   \n..                                                 ...   \n495  [, mia, daniels, praktische, führerscheinprüfu...   \n496  [imtv, guuude, heute, letzte, warmup, qualifie...   \n497  [th, servicetweet, discoursmaschine, corona, q...   \n498                 [gehts, heute, gut, entfolgt, tag]   \n499  [, obwohl, anschuldigung, ardmagazins, panoram...   \n\n                                      Tweet_lemmatized  \n0                     [mal, Frage, heute, Ruhe, Sturm]  \n1    [unterwegs, gut, Blockchainopfer, schon, werde...  \n2    [heute, Grundrecht, Tag, Haft, dürfen, Vergess...  \n3                                 [laufen, heute, Bvb]  \n4                                [Bock, heute, Bvbbmg]  \n..                                                 ...  \n495  [Mia, Daniel, praktisch, Führerscheinprüfung, ...  \n496  [Imtv, Guuude, heute, letzter, Warmup, Qualifi...  \n497  [th, Servicetweet, Discoursmaschine, Corona, Q...  \n498                [gehts, heute, gut, entfolgen, Tag]  \n499  [obwohl, Anschuldigung, Ardmagazins, Panorama,...  \n\n[500 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Tweet_tokenized</th>\n      <th>Tweet_nonstop</th>\n      <th>Tweet_lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mal eine Frage\\nIst das heute die Ruhe vor od...</td>\n      <td>[, mal, eine, frage, ist, das, heute, die, ruh...</td>\n      <td>[, mal, frage, heute, ruhe, sturm]</td>\n      <td>[mal, Frage, heute, Ruhe, Sturm]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>unterwegs   Alles gut  blockchainopfer war ich...</td>\n      <td>[unterwegs, alles, gut, blockchainopfer, war, ...</td>\n      <td>[unterwegs, gut, blockchainopfer, schon, wurde...</td>\n      <td>[unterwegs, gut, Blockchainopfer, schon, werde...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Heute sind die Grundrechte  Tage in Haft Es d...</td>\n      <td>[, heute, sind, die, grundrechte, tage, in, ha...</td>\n      <td>[, heute, grundrechte, tage, haft, darf, verge...</td>\n      <td>[heute, Grundrecht, Tag, Haft, dürfen, Vergess...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Läuft heute BVB</td>\n      <td>[läuft, heute, bvb]</td>\n      <td>[läuft, heute, bvb]</td>\n      <td>[laufen, heute, Bvb]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Also  hat Bock heute\\n\\n\\n BVBBMG</td>\n      <td>[also, hat, bock, heute, bvbbmg]</td>\n      <td>[bock, heute, bvbbmg]</td>\n      <td>[Bock, heute, Bvbbmg]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>Mia Daniels und die praktische Führerscheinp...</td>\n      <td>[, mia, daniels, und, die, praktische, führers...</td>\n      <td>[, mia, daniels, praktische, führerscheinprüfu...</td>\n      <td>[Mia, Daniel, praktisch, Führerscheinprüfung, ...</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>iMTV Guuude \\nheute ist der letzte Warmup Qual...</td>\n      <td>[imtv, guuude, heute, ist, der, letzte, warmup...</td>\n      <td>[imtv, guuude, heute, letzte, warmup, qualifie...</td>\n      <td>[Imtv, Guuude, heute, letzter, Warmup, Qualifi...</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>th Servicetweet DiscoursMaschine Corona Querde...</td>\n      <td>[th, servicetweet, discoursmaschine, corona, q...</td>\n      <td>[th, servicetweet, discoursmaschine, corona, q...</td>\n      <td>[th, Servicetweet, Discoursmaschine, Corona, Q...</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>Mir gehts heute nicht gut Entfolgt an einem an...</td>\n      <td>[mir, gehts, heute, nicht, gut, entfolgt, an, ...</td>\n      <td>[gehts, heute, gut, entfolgt, tag]</td>\n      <td>[gehts, heute, gut, entfolgen, Tag]</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>Obwohl sich die Anschuldigung des ARDMagazins...</td>\n      <td>[, obwohl, sich, die, anschuldigung, des, ardm...</td>\n      <td>[, obwohl, anschuldigung, ardmagazins, panoram...</td>\n      <td>[obwohl, Anschuldigung, Ardmagazins, Panorama,...</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vorverarbeitung von  txt\n",
    "\n",
    "def removeEmojis(txt):\n",
    "     regrex_pattern = re.compile(pattern = \"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "        \"]+\", flags = re.UNICODE)\n",
    "     return regrex_pattern.sub(r'',txt)\n",
    "\n",
    "def removeMentions(txt):\n",
    "    return re.sub(r'@[A-Za-z0-9]+', '' ,txt)\n",
    "\n",
    "def removeHashtags(txt):\n",
    "    return re.sub(r'#','',txt)\n",
    "\n",
    "def removeRetweet(txt):\n",
    "    return re.sub(r'RT[\\s]+','',txt)\n",
    "\n",
    "def removeHyperlinks(txt):\n",
    "    return re.sub(r'https?:\\/\\/\\S+','',txt)\n",
    "\n",
    "def removePunctuations(txt):\n",
    "    txt  = \"\".join([char for char in txt if char not in string.punctuation])\n",
    "    txt = re.sub('[0-9]+', '', txt)\n",
    "    return txt\n",
    "\n",
    "def txtVerarbeitung(txt):\n",
    "    txt = removeEmojis(txt)\n",
    "    txt = removeMentions(txt)\n",
    "    txt = removeHashtags(txt)\n",
    "    txt = removeRetweet(txt)\n",
    "    txt = removeHyperlinks(txt)\n",
    "    txt = removePunctuations(txt)\n",
    "    return txt\n",
    "\n",
    "def tokenization(txt):\n",
    "    txt = re.split('\\W+', txt)\n",
    "    return txt\n",
    "\n",
    "stopword = nltk.corpus.stopwords.words('german')\n",
    "def removeStopwords(txt):\n",
    "    txt = [word for word in txt if word not in stopword]\n",
    "    return txt\n",
    "\n",
    "hannover = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "def lemmatizer(txt):\n",
    "    lemmatized = []\n",
    "    for word in txt:\n",
    "        if word and word.strip():\n",
    "            result = hannover.analyze(word)[0]\n",
    "            lemmatized.append(result)\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "df['Tweet'] = df['Tweet'].apply(txtVerarbeitung)\n",
    "df['Tweet_tokenized'] = df['Tweet'].apply(lambda x: tokenization(x.lower()))\n",
    "df['Tweet_nonstop'] = df['Tweet_tokenized'].apply(removeStopwords)\n",
    "df['Tweet_lemmatized'] = df['Tweet_nonstop'].apply(lemmatizer)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}